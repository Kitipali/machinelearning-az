





import numpy as np
import matplotlib.pyplot as plt
import pandas as pd






dataset = pd.read_csv('50_Startups.csv')
X = dataset.iloc[:, :-1].values
y = dataset.iloc[:, -1].values


print("Shape antes del OHE:",X.shape)


dataset.head(5)


print(X)


print(y)











import sklearn
print(sklearn.__version__)



from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
ct = ColumnTransformer(transformers=[('ohe', OneHotEncoder(drop='first', handle_unknown='ignore', sparse_output=False), [3])], remainder='passthrough')


# transformers=[('encoder', OneHotEncoder(), [3])] 
  # Se crea un transformador llamado "encoder".
  # Aplica OneHotEncoder a la columna de índice 3 (State).
  # handle_unknown='ignore' evita errores si aparece una categoría nueva en test/predicción.
  # drop='first': elimina una dummy por categoría. Evitamos así la trampa de las variables dummies

  # sparse_output=False para que no sea una matriz dispersa sino numpy

  # remainder='passthrough' Significa que el resto de las columnas (las numéricas) se dejan igual (pasan tal cual).

X = ct.fit_transform(X)

# Aquí se aplica la transformación: fit aprende las categorías únicas en la columna State. transform las convierte en columnas binarias (dummy).
# np.array(...) Convierte el resultado en un numpy.ndarray (porque fit_transform devuelve un objeto tipo sparse matrix por defecto).






print(X)





from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)





from sklearn.linear_model import LinearRegression
regression = LinearRegression()
regression.fit(X_train, y_train)





y_pred = regression.predict(X_test)
np.set_printoptions(precision=2)
print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))








# Construir el modelo de RLM utilizando la eliminación hacia atrás

import statsmodels.api as sm

# X ya debe ser 2D y numérica (p. ej., tras el OneHotEncoder con drop='first')
X_opt = sm.add_constant(X, has_constant='add').astype(float)  # mete la constante en la col 0

reg = sm.OLS(y, X_opt).fit()



reg.summary()



# Tenemos que eliminar la variable 2 (x2)


# Quitar x2 (recuerda: 0=const, 1=x1, 2=x2, ...)
X_opt =np.delete(X_opt,2, axis =1)  
reg = sm.OLS(y, X_opt).fit()
reg.summary()


# Tenemos que eliminar la variable 1
# Quitar x2 (recuerda: 0=const, 1=x1, 2=x2, ...)
X_opt =np.delete(X_opt,1, axis =1)  
reg = sm.OLS(y, X_opt).fit()
reg.summary()



# Tenemos que eliminar la variable 2
# Quitar x2 (recuerda: 0=const, 1=x1, 2=x2, ...)
X_opt =np.delete(X_opt,2, axis =1)  
reg = sm.OLS(y, X_opt).fit()
reg.summary()




