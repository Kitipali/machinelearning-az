{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbe7ea07-c9ae-4845-946b-4df27bfd192f",
   "metadata": {},
   "source": [
    "Plantilla de Pre Procesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1761d626-34e6-4e92-844b-721c3bd3d812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cómo importar las librerías\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as  plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2f81f19-6a39-4092-b0d5-11348366e945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Repos Github\\machinelearning-az\\update\\Part 1 - Data Preprocessing\\Section 2 -------------------- Part 1 - Data Preprocessing --------------------\\Python\n"
     ]
    }
   ],
   "source": [
    "# Importar el data set\n",
    "%cd \"D:\\Repos Github\\machinelearning-az\\update\\Part 1 - Data Preprocessing\\Section 2 -------------------- Part 1 - Data Preprocessing --------------------/Python\"\n",
    "dataset = pd.read_csv('Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc09b6d0-db5c-4d7e-a4f3-cbab68bb3eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary Purchased\n",
       "0   France  44.0  72000.0        No\n",
       "1    Spain  27.0  48000.0       Yes\n",
       "2  Germany  30.0  54000.0        No\n",
       "3    Spain  38.0  61000.0        No\n",
       "4  Germany  40.0      NaN       Yes"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6608d71a-36d2-4d3f-95f0-b85549997af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable independiente = columnas Country + Age+ Salary \n",
    "#Variable dependiente = columna Purchased\n",
    "X = dataset.iloc[:,:-1].values \n",
    "#Todas las filas y todas las columnas salvo la última\n",
    "#.values porque queremos extraer los valores, no las posiciones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7a78623-b399-4706-9cdc-fb9df067cdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y= dataset.iloc[:,3].values #Selecciona tercera columna "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f6abbba-e13f-45c0-9e63-c6d90dc24833",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos de X después de manejar valores faltantes:\n",
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 63777.77777777778]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' 38.77777777777778 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "# Tratamiento de los NAs\n",
    "from sklearn.impute import SimpleImputer #Como no queremos toda la librería sino sólo una parte. Imputer calcula los datos faltantes (NAs\n",
    "# Ahora creamos un objeto de esta clase (Imputer)\n",
    "imputer = SimpleImputer(missing_values=np.nan,strategy=\"mean\") #missing_values=np.nan puedo no ponerlo\n",
    "#strategy -> cómo voy a sustituir los valores desconocidos. En este caso media\n",
    "imputer.fit(X[:, 1:3])  # Aplicamos el ajuste a las columnas 1 y 2 (índices 1:3 porque el último no lo coge)\n",
    "X[:, 1:3] = imputer.transform(X[:, 1:3])  # Reemplazamos los valores nulos en las columnas seleccionadas. Tb vale imputer.fit_transform\n",
    "print(\"Datos de X después de manejar valores faltantes:\")\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb0b6ea3-2a98-463a-bed9-f428b1adda17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codifcar datos categóricos\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22077ad1-be41-434a-b955-f8341ec3890a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos de X después de la codificación OneHot:\n",
      "[[1.0 0.0 1.0 0.0 1.0 0.0 0.0 44.0 72000.0]\n",
      " [0.0 1.0 0.0 1.0 0.0 0.0 1.0 27.0 48000.0]\n",
      " [0.0 1.0 0.0 1.0 0.0 1.0 0.0 30.0 54000.0]\n",
      " [0.0 1.0 0.0 1.0 0.0 0.0 1.0 38.0 61000.0]\n",
      " [0.0 1.0 0.0 1.0 0.0 1.0 0.0 40.0 63777.77777777778]\n",
      " [1.0 0.0 1.0 0.0 1.0 0.0 0.0 35.0 58000.0]\n",
      " [0.0 1.0 0.0 1.0 0.0 0.0 1.0 38.77777777777778 52000.0]\n",
      " [1.0 0.0 1.0 0.0 1.0 0.0 0.0 48.0 79000.0]\n",
      " [0.0 1.0 0.0 1.0 0.0 1.0 0.0 50.0 83000.0]\n",
      " [1.0 0.0 1.0 0.0 1.0 0.0 0.0 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "#Aplicamos OneHotEncoder a primera columna (0)\n",
    "ct = ColumnTransformer(\n",
    "    transformers=[('encoder', OneHotEncoder(),[0])],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "#ColumnTransformer([...], remainder='passthrough')\n",
    "# significa Aplica distintos transformadores a columnas concretas y decide qué hacer con el resto:\n",
    "#La lista transformers=[('encoder', OneHotEncoder(), [0])] \n",
    "# dice: “aplica el OneHotEncoder a la columna 0”\n",
    "# remainder='passthrough' significa: las demás columnas se mantienen sin tocar\n",
    "X=np.array(ct.fit_transform(X))\n",
    "# fit: el encoder aprende qué categorías existen y en qué orden.\n",
    "# transform: genera la matriz codificada y concatena las columnas restantes.\n",
    "# Transformamos X y lo convertimos a un array de NumPy\n",
    "print(\"Datos de X después de la codificación OneHot:\")\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf362973-fa5a-4312-889e-e84abbae6e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos de y después de la codificación:\n",
      "[0 1 0 0 1 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Codificación de la variable dependiente (y)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)  # Transformamos las etiquetas categóricas en valores numéricos\n",
    "print(\"Datos de y después de la codificación:\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b35f5a-50e8-45bb-9d25-2bb175ebab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir el data set en conjunto de entrenamiento y conjunto de testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f90222b1-6050-44cd-a1fc-dad02799cdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "# x= variable independiente\n",
    "# y= variable dependiente\n",
    "# test_size =0.2 eserva ~20% de las filas para test y ~80% para train (redondea a un entero según el tamaño del dataset)\n",
    "# random_state=0 → fija la semilla del aleatorizador para que la misma partición se repita cada vez que ejecutes el código (reproducibilidad).\n",
    "# Devuelve:\n",
    "# X_train y y_train: datos para entrenar el modelo\n",
    "# X_test y y_test: datos nunca vistos que usarás para evaluar el modelo.\n",
    "# En clasificación, añade stratify=y para mantener la misma proporción de clases en train y test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7f3957b-0a21-4038-8dbc-0c49e42f0fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 40.0, 63777.77777777778],\n",
       "       [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 37.0, 67000.0],\n",
       "       [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 27.0, 48000.0],\n",
       "       [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 38.77777777777778, 52000.0],\n",
       "       [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 48.0, 79000.0],\n",
       "       [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 38.0, 61000.0],\n",
       "       [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 44.0, 72000.0],\n",
       "       [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 35.0, 58000.0]], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c819060a-b087-4591-8d6e-4edf7b480e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjunto de entrenamiento después del escalado de características:\n",
      "[[0.0 1.0 0.0 1.0 -1.0 2.6457513110645907 -0.7745966692414833\n",
      "  0.26306757317135365 0.12381478548381816]\n",
      " [1.0 0.0 1.0 -1.0 1.0 -0.37796447300922714 -0.7745966692414833\n",
      "  -0.2535014796014863 0.46175631762788527]\n",
      " [0.0 1.0 0.0 1.0 -1.0 -0.37796447300922714 1.2909944487358056\n",
      "  -1.9753983221776197 -1.5309334063940299]\n",
      " [0.0 1.0 0.0 1.0 -1.0 -0.37796447300922714 1.2909944487358056\n",
      "  0.052613514634270886 -1.111419780284153]\n",
      " [1.0 0.0 1.0 -1.0 1.0 -0.37796447300922714 -0.7745966692414833\n",
      "  1.6405850472322603 1.7202971959575157]\n",
      " [0.0 1.0 0.0 1.0 -1.0 -0.37796447300922714 1.2909944487358056\n",
      "  -0.08131179534387295 -0.16751412153693]\n",
      " [1.0 0.0 1.0 -1.0 1.0 -0.37796447300922714 -0.7745966692414833\n",
      "  0.9518263102018071 0.9861483502652313]\n",
      " [1.0 0.0 1.0 -1.0 1.0 -0.37796447300922714 -0.7745966692414833\n",
      "  -0.5978808481167129 -0.4821493411193376]]\n",
      "Conjunto de prueba después del escalado de características:\n",
      "[[0.0 1.0 0.0 1.0 -1.0 2.6457513110645907 -0.7745966692414833\n",
      "  -1.4588292694047797 -0.9016629672292145]\n",
      " [0.0 1.0 0.0 1.0 -1.0 2.6457513110645907 -0.7745966692414833\n",
      "  1.9849644157474868 2.1398108220673926]]\n"
     ]
    }
   ],
   "source": [
    "#Escalado de variables\n",
    "\n",
    "# Estandarizamos los valores para que tengan media 0 y desviación estándar 1. Valores entre -1 y 1\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train[:, 3:] = sc.fit_transform(X_train[:, 3:])  # Ajustamos y transformamos las características numéricas del conjunto de entrenamiento\n",
    "X_test[:, 3:] = sc.transform(X_test[:, 3:])  # Transformamos el conjunto de prueba usando el ajuste del conjunto de entrenamiento\n",
    "print(\"Conjunto de entrenamiento después del escalado de características:\")\n",
    "print(X_train)\n",
    "print(\"Conjunto de prueba después del escalado de características:\")\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fe8efc-0d13-413e-aad4-f9a679e82de8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ML)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
